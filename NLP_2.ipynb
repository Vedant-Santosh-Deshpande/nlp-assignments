{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Perform bag-of-words approach (count occurrence, normalized count occurrence), TF-IDF on\n",
        "data. Create embeddings using Word2Vec**\n"
      ],
      "metadata": {
        "id": "KGgRyK1wVzYj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#1. Bag-of-Words (BoW)\n",
        "\n",
        "#In this method, we convert each document into a \"bag\" of words (ignoring grammar, word order, and even capitalization),\n",
        "#and we count how many times each word appears in the document."
      ],
      "metadata": {
        "id": "HN4DZUVwV5pq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#2. TF-IDF (Term Frequency - Inverse Document Frequency)\n",
        "\n",
        "# TF-IDF is a measure that helps identify the importance of a word in a document relative to the entire collection of documents.\n",
        "# Words that appear often in one document but rarely in others are considered important."
      ],
      "metadata": {
        "id": "eaPYU2P5Yb-r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#3. Word2Vec\n",
        "\n",
        "#Word2Vec is a technique that converts words into vectors (numbers), and words with similar meanings have\n",
        "#similar vectors. This is done by training a machine learning model on your data."
      ],
      "metadata": {
        "id": "s5hKXB_oZ5a8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Install necessary libraries\n",
        "!pip install scikit-learn gensim  # Install required libraries in Google Colab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBvMcx3PaVuB",
        "outputId": "18fe0499-acac-440f-84c6-50141bb3d0f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from gensim.models import Word2Vec\n"
      ],
      "metadata": {
        "id": "mfzkBBgzaWsF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample data: list of documents (text)\n",
        "documents = [\n",
        "    \"I love programming in Python\",\n",
        "    \"Python is a great programming language\",\n",
        "    \"I love coding\",\n",
        "    \"I prefer Python over other programming languages\",\n",
        "    \"Python programming is fun\"\n",
        "]\n"
      ],
      "metadata": {
        "id": "8zY3-axcaZkF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. **Bag-of-Words (BoW) Approach**:\n",
        "# We use CountVectorizer to convert the text into word counts\n",
        "vectorizer_bow = CountVectorizer()  # Initialize the vectorizer\n",
        "X_bow = vectorizer_bow.fit_transform(documents)  # Fit the model and transform the documents\n"
      ],
      "metadata": {
        "id": "o-rCZ4zSafk3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the Bag-of-Words matrix (each row represents a document, each column a word)\n",
        "print(\"Bag-of-Words Matrix:\")\n",
        "print(X_bow.toarray())  # .toarray() converts the sparse matrix to a dense array\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPW0M9f6ai3o",
        "outputId": "c4370f78-21ae-4c05-cd90-1194ee46d948"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bag-of-Words Matrix:\n",
            "[[0 0 0 1 0 0 0 1 0 0 0 1 1]\n",
            " [0 0 1 0 1 1 0 0 0 0 0 1 1]\n",
            " [1 0 0 0 0 0 0 1 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 1 0 1 1 1 1 1]\n",
            " [0 1 0 0 1 0 0 0 0 0 0 1 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. **TF-IDF Approach**:\n",
        "# We use TfidfVectorizer to calculate the importance of each word\n",
        "vectorizer_tfidf = TfidfVectorizer()  # Initialize the vectorizer\n",
        "X_tfidf = vectorizer_tfidf.fit_transform(documents)  # Fit the model and transform the documents"
      ],
      "metadata": {
        "id": "CzBwQyKCarYh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the TF-IDF matrix (importance of each word in the documents)\n",
        "print(\"\\nTF-IDF Matrix:\")\n",
        "print(X_tfidf.toarray())  # .toarray() converts the sparse matrix to a dense array"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMoYyHM2a23b",
        "outputId": "a1f692f9-ce3a-4629-a252-b888d452036e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TF-IDF Matrix:\n",
            "[[0.         0.         0.         0.6614376  0.         0.\n",
            "  0.         0.53364369 0.         0.         0.         0.3726424\n",
            "  0.3726424 ]\n",
            " [0.         0.         0.55167715 0.         0.44508965 0.55167715\n",
            "  0.         0.         0.         0.         0.         0.31080528\n",
            "  0.31080528]\n",
            " [0.77828292 0.         0.         0.         0.         0.\n",
            "  0.         0.62791376 0.         0.         0.         0.\n",
            "  0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.46449871 0.         0.46449871 0.46449871 0.46449871 0.26169047\n",
            "  0.26169047]\n",
            " [0.         0.6614376  0.         0.         0.53364369 0.\n",
            "  0.         0.         0.         0.         0.         0.3726424\n",
            "  0.3726424 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. **Word2Vec Approach**:\n",
        "# Word2Vec converts words to numerical vectors. We train a model on the documents.\n",
        "# First, we split the documents into a list of words.\n",
        "tokenized_docs = [doc.lower().split() for doc in documents]  # Convert each document to a list of lowercase words"
      ],
      "metadata": {
        "id": "upmEHUt-a54Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create and train the Word2Vec model using the tokenized documents\n",
        "model_w2v = Word2Vec(sentences=tokenized_docs, vector_size=10, window=3, min_count=1)"
      ],
      "metadata": {
        "id": "xlKgjjUvbB6l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the word vectors (embeddings) for a few words\n",
        "print(\"\\nWord2Vec Embeddings:\")\n",
        "for word in [\"python\", \"programming\", \"love\"]:  # Example words to check\n",
        "    print(f\"Embedding for '{word}': {model_w2v.wv[word]}\")  # Get the vector (embedding) for the word\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YkA5blqbbEZo",
        "outputId": "665ca309-964c-4c22-9a6e-a4eedb28a3c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Word2Vec Embeddings:\n",
            "Embedding for 'python': [-0.00536227  0.00236431  0.0510335   0.09009273 -0.0930295  -0.07116809\n",
            "  0.06458873  0.08972988 -0.05015428 -0.03763372]\n",
            "Embedding for 'programming': [ 0.07380123 -0.01533396 -0.04536377  0.06553721 -0.04859911 -0.01815925\n",
            "  0.02876429  0.00991821 -0.08284786 -0.09448329]\n",
            "Embedding for 'love': [-0.0960355   0.05007293 -0.08759586 -0.04391825 -0.000351   -0.00296181\n",
            " -0.0766124   0.09614743  0.04982058  0.09233143]\n"
          ]
        }
      ]
    }
  ]
}