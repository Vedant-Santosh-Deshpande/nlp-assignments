{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UCEJiAk6kDbs"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if GPU is available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGMbFfoakT50",
        "outputId": "3d883849-9785-4b39-c56c-be9d084bd657"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample dataset (replace with real dataset)\n",
        "data = [\n",
        "    (\"The cat sat on the mat\", 0),\n",
        "    (\"Dogs are loyal animals\", 1),\n",
        "    (\"Transformers are powerful models\", 1),\n",
        "    (\"Pytorch makes deep learning easy\", 0),\n",
        "]\n",
        "vocab = list(set(word for sentence, _ in data for word in sentence.split()))\n",
        "word2idx = {word: idx for idx, word in enumerate(vocab)}"
      ],
      "metadata": {
        "id": "2X9oYopVkZxq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert dataset into token indices\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, data, word2idx, max_len=None):  # Add max_len parameter\n",
        "        self.data = [(torch.tensor([word2idx[word] for word in sentence.split()], dtype=torch.long), label)\n",
        "                     for sentence, label in data]\n",
        "        self.max_len = max_len if max_len else max(len(x[0]) for x in self.data)  # Calculate or use provided max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Pad sequences to max_len\n",
        "        tensor, label = self.data[idx]\n",
        "        padded_tensor = torch.zeros(self.max_len, dtype=torch.long)\n",
        "        padded_tensor[:len(tensor)] = tensor\n",
        "        return padded_tensor, label  # Return padded tensor\n",
        "\n",
        "dataset = TextDataset(data, word2idx)\n",
        "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)"
      ],
      "metadata": {
        "id": "mYpMgQjukdqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformer Model Definition\n",
        "class TransformerModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, num_heads, num_layers, hidden_dim, num_classes):\n",
        "        super(TransformerModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
        "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=embed_dim, nhead=num_heads, dim_feedforward=hidden_dim)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=num_layers)\n",
        "        self.fc = nn.Linear(embed_dim, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)  # Shape: (batch_size, seq_len, embed_dim)\n",
        "        x = x.permute(1, 0, 2)  # Required shape for Transformer (seq_len, batch_size, embed_dim)\n",
        "        x = self.transformer_encoder(x)  # Apply transformer\n",
        "        x = x.mean(dim=0)  # Global Average Pooling\n",
        "        x = self.fc(x)  # Fully connected layer\n",
        "        return x"
      ],
      "metadata": {
        "id": "nFR860UkkhDa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "vocab_size = len(vocab)\n",
        "embed_dim = 32\n",
        "num_heads = 2\n",
        "num_layers = 2\n",
        "hidden_dim = 64\n",
        "num_classes = 2"
      ],
      "metadata": {
        "id": "kThWObD9kmXu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model, Loss, Optimizer\n",
        "model = TransformerModel(vocab_size, embed_dim, num_heads, num_layers, hidden_dim, num_classes).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqxh54KtkpcE",
        "outputId": "f47c674e-26fe-4c93-ae62-56224213868b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Loop\n",
        "def train_model(model, dataloader, criterion, optimizer, epochs=10):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        for inputs, labels in dataloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss:.4f}\")\n",
        "\n",
        "train_model(model, dataloader, criterion, optimizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jBbTYhoaktkV",
        "outputId": "243a6ae8-1668-4f23-b3fb-7976163c78af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 1.4913\n",
            "Epoch 2/10, Loss: 1.2865\n",
            "Epoch 3/10, Loss: 1.0807\n",
            "Epoch 4/10, Loss: 0.9782\n",
            "Epoch 5/10, Loss: 0.8233\n",
            "Epoch 6/10, Loss: 0.7538\n",
            "Epoch 7/10, Loss: 0.6654\n",
            "Epoch 8/10, Loss: 0.5135\n",
            "Epoch 9/10, Loss: 0.4718\n",
            "Epoch 10/10, Loss: 0.3672\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save Model\n",
        "torch.save(model.state_dict(), \"transformer_model.pth\")\n",
        "print(\"Model saved successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6ZGFmbalIHd",
        "outputId": "84bf7d6f-007c-42fd-e8e0-644907985c83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved successfully!\n"
          ]
        }
      ]
    }
  ]
}